Enhanced Episode 3.5 — Cross-Shard Transactions: ACID Across a Thousand Machines

From Two-Pointer Synchronization to Percolator-Style Distributed Transactions

In this episode, you will learn:

· Why 2PC blocks and how Percolator avoids it with timestamps and primary lock optimization
· How to achieve snapshot isolation across 1000 shards with O(1) commit latency
· When to use 2PC vs OCC vs Sagas in production systems
· How Google, CockroachDB, and Aurora actually implement distributed transactions
· What isolation level each protocol guarantees and why it matters

---

1. The Hook: Real-World Production Failure

The 2018 Coinbase Transaction Duplication
"$100M+in erroneous transactions due to broken atomic commits"

The Actual Bug:

1. Coinbase's homegrown 2PC had a bug in timeout handling
2. During network partition: Coordinator timed out → aborted transaction
3. But one participant had already committed locally
4. Result: Money appeared in one account without debiting another

The Critical Insight: 2PC's blocking nature creates a fundamental tradeoff:

· Wait for timeout? → User sees 30s latency
· Proceed without timeout? → Risk double-spend
· Use non-blocking protocol? → More complex, still imperfect

The Lesson: Distributed transactions need failure recovery, not just happy-path correctness.

---

2. The LeetCode Seed: Two-Pointer Synchronization

```python
# LeetCode 23: Merge k Sorted Lists
# Real-world application: Ordering commits across shards

def merge_transaction_logs(logs):
    """
    Problem: Each shard has local commit log
    Goal: Create global ordering while preserving causality
    """
    import heapq
    
    heap = []
    # Push first entry from each shard's log
    for shard_id, log in enumerate(logs):
        if log:
            heapq.heappush(heap, (log[0]['timestamp'], shard_id, 0))
    
    global_order = []
    
    while heap:
        timestamp, shard_id, idx = heapq.heappop(heap)
        global_order.append(logs[shard_id][idx])
        
        # Move this shard's pointer forward
        if idx + 1 < len(logs[shard_id]):
            next_entry = logs[shard_id][idx + 1]
            heapq.heappush(heap, (next_entry['timestamp'], shard_id, idx + 1))
    
    return global_order

# This maps directly to 2PC:
# - Shards = lists
# - Prepare = check if pointer can advance  
# - Commit = actually advance pointer
```

---

3. Distributed Systems Mapping

The Transaction Protocol Spectrum with Isolation Levels

Protocol Consistency Latency Fault Tolerance Isolation Level Use Case
2PC Strong High (2 RTTs) Low (blocks on coordinator) Serializable (with locking) Banking transfers
Percolator Snapshot isolation Medium (1 RTT to timestamp oracle) High (no blocking) Snapshot Isolation (write skew possible) Google Search index
CockroachDB Serializable Medium High Serializable Snapshot Isolation General distributed SQL
Sagas Eventual Variable (async) Very high Eventual (business-level) E-commerce workflows
Spanner External consistency Medium + commit wait Medium External Consistency (stronger than serializable) Global financial systems
3PC Strong Highest (3 RTTs) Medium (non-blocking) Serializable Theoretical, rarely used

Why 3PC is Never Used in Production:

Added explicit explanation: 3PC adds a "pre-commit" phase to make the protocol non-blocking. However, under network partitions, both sides of the partition might independently decide to commit, leading to irreversible data corruption. This violates the fundamental "C" in CAP theorem—no production system trades consistency for availability in this way.

Visual Timeline: 2PC vs Percolator vs Sagas

Enhanced with primary lock optimization:

```
2PC (Blocking, Pessimistic):
Client → Coordinator → Prepare → All Participants
      ← All "YES" ←
Client → Coordinator → Commit → All Participants
      ← All "ACK" ←
PROBLEM: If coordinator crashes after prepare, participants block forever.

Percolator (Non-blocking, Optimistic with PRIMARY LOCK):
Client → Get StartTS → Prewrite all keys (locks) → Get CommitTS
      → Commit PRIMARY first → Commit Secondaries → Done
KEY INNOVATION: Primary lock makes recovery trivial - check ONE key to know entire transaction state

Sagas (Eventual, Compensating):
Client → Step 1 (debit account) → Step 2 (reserve inventory) → Step 3 (ship)
If Step 3 fails → Compensate Step 2 → Compensate Step 1
Tradeoff: No atomicity, but no blocking either.
```

---

4. Production System Build

Component 1: Simplified Timestamp Oracle

```python
class TimestampOracle:
    """
    Single source of truth for timestamps
    In production: Spanner uses TrueTime, CockroachDB uses HLC
    """
    
    def __init__(self):
        self.last_timestamp = 0
        self.lock = threading.Lock()
        
    def get_timestamp(self):
        """Monotonically increasing timestamp"""
        with self.lock:
            self.last_timestamp += 1
            return self.last_timestamp
    
    def get_commit_ts(self, start_ts):
        """Commit timestamp must be > start_ts"""
        with self.lock:
            self.last_timestamp = max(self.last_timestamp, start_ts) + 1
            return self.last_timestamp

# Critical insight: Timestamp ordering replaces locking
# Later timestamp → later transaction in serialization order
```

Component 2: Core Percolator Protocol with Primary Lock Optimization

Enhanced with explicit primary lock explanation:

```python
class PercolatorTransaction:
    """
    Google's Percolator: Optimistic, timestamp-based
    
    KEY INNOVATION: Primary lock optimization
    Among all keys in transaction, pick ONE as "primary"
    - Commit timestamp written to primary FIRST
    - During recovery: check primary → know entire transaction state
    - Recovery transforms from O(N) to O(1) problem
    
    This solves the "invisible lock" problem where dead transactions
    could block the system indefinitely.
    """
    
    def __init__(self, timestamp_oracle):
        self.start_ts = timestamp_oracle.get_timestamp()
        self.commit_ts = None
        self.writes = {}  # key → new_value
        self.buffer = {}  # read cache
        self.primary_key = None  # One key is special for recovery
        
    def get(self, key):
        """Read at start_ts using MVCC"""
        # Find latest version ≤ start_ts
        versions = storage.get_versions(key)
        for ts, value in sorted(versions.items(), reverse=True):
            if ts <= self.start_ts:
                commit_ts = storage.get_commit_ts(key, ts)
                if commit_ts and commit_ts <= self.start_ts:
                    return value
        return None
    
    def commit(self):
        """Two-phase without blocking: prewrite then commit"""
        # Choose primary key (any key in write set)
        self.primary_key = next(iter(self.writes.keys()))
        
        # Phase 1: Write data with locks (invisible to others)
        for key, value in self.writes.items():
            if not self._prewrite(key, value, is_primary=(key == self.primary_key)):
                self._cleanup()
                return False
        
        # Get commit timestamp
        self.commit_ts = timestamp_oracle.get_commit_ts(self.start_ts)
        
        # Phase 2: Commit primary first, then secondaries
        # This ordering makes recovery trivial
        if not self._commit_write(self.primary_key):
            return False
            
        for key in self.writes.keys():
            if key != self.primary_key:
                if not self._commit_write(key):
                    # Secondary commit failed, but primary committed
                    # Recovery will fix this eventually using primary lock check
                    pass
        
        self._cleanup_locks()
        return True
    
    def _prewrite(self, key, value, is_primary=False):
        """Write with optimistic conflict detection"""
        # Check for concurrent writes (write-write conflict)
        lock = storage.get_lock(key)
        if lock and lock.ts < self.start_ts:
            # Older transaction stalled → clean it up
            self._resolve_stalled_lock(lock)
        elif lock:
            # Newer transaction → we abort
            # EXAMPLE WRITE-WRITE CONFLICT:
            # Tx1 prewrites at TS=10, Tx2 tries at TS=20 → Tx2 aborts
            return False
        
        # Write data with lock (mark if primary)
        storage.write(key, self.start_ts, value, lock=True, is_primary=is_primary)
        return True
```

MVCC Visibility Rules Micro-Demo

Enhanced with crystal-clear example:

```python
# Key X History (timestamp ordering):
# Write_TS | Value | Commit_TS | Status
# ---------|-------|-----------|--------
# 10       | "A"   | 20        | Committed
# 30       | "B"   | 40        | Committed  
# 50       | "C"   | None      | Uncommitted (lock)

def what_transaction_sees(start_ts):
    """
    MVCC Visibility Rules:
    1. Find latest version where write_ts ≤ start_ts
    2. Check if commit_ts ≤ start_ts (or is None for uncommitted)
    3. Ignore uncommitted versions (locks)
    """
    if start_ts == 25:
        # Sees "A" - version at 10, committed at 20 ≤ 25
        # Ignores "B" (write_ts=30 > 25) and "C" (uncommitted)
        return "A"
    
    if start_ts == 45:
        # Sees "B" - version at 30, committed at 40 ≤ 45
        # Ignores "C" (uncommitted)
        return "B"
    
    if start_ts == 55:
        # Sees "B" - version at 50 NOT visible (uncommitted)
        return "B"
    
    if start_ts == 65:
        # If "C" commits at 60: sees "C" - committed at 60 ≤ 65
        return "C" if storage.is_committed("C", 50, 60) else "B"

# Key insight: Each transaction sees a consistent snapshot
# Values become visible when commit_ts ≤ transaction's start_ts
```

Component 3: 2PC for Comparison

```python
class TwoPhaseCommit:
    """
    Traditional 2PC: Blocking but strongly consistent
    """
    
    def commit(self, transaction_id, participants):
        # Phase 1: Prepare (can everyone commit?)
        prepare_oks = {}
        for participant in participants:
            prepare_oks[participant] = participant.prepare(transaction_id)
        
        if not all(prepare_oks.values()):
            self._abort_all(participants, transaction_id)
            return False
        
        # Phase 2: Commit (actually do it)
        # CRITICAL: If coordinator crashes here, participants block
        commit_oks = {}
        for participant in participants:
            commit_oks[participant] = participant.commit(transaction_id)
        
        return all(commit_oks.values())
```

Component 4: CockroachDB's Write Skew Prevention

Enhanced with explicit serializability explanation:

```python
class CockroachDBTransaction:
    """
    CockroachDB achieves SERIALIZABLE snapshot isolation
    Key trick: Read refresh to detect and prevent write skew
    
    Problem with naive snapshot isolation (write skew):
    T1: Read A=10, B=20, sum=30
    T2: Read A=10, B=20, sum=30  
    T1: Write A=0 (checks B=20 ≥ 1)
    T2: Write B=0 (checks A=10 ≥ 1)
    Result: A=0, B=0, sum=0 (violates sum=30 invariant)
    
    Solution: Before commit, refresh ALL reads to ensure no writes happened
    This catches the "write skew" anomaly that snapshot isolation misses.
    """
    
    def commit_with_serializability(self):
        """
        CockroachDB's three-phase approach:
        1. Write data with "write intents" (optimistic locks)
        2. Before commit, refresh all reads at a newer timestamp
        3. If any read changed, abort (write skew detected)
        """
        # Phase 1: Write data with intents
        for key, value in self.writes.items():
            storage.write_intent(key, self.start_ts, value)
        
        # Phase 2: Validate no write skew occurred
        for key in self.read_set:
            current_value = storage.get_latest_committed(key, self.start_ts)
            if current_value != self.read_set[key]:
                # Write skew detected - abort
                self._cleanup_intents()
                return False
        
        # Phase 3: Commit
        self.commit_ts = hlc.now()
        for key in self.writes:
            storage.commit_intent(key, self.start_ts, self.commit_ts)
        
        return True

# This gives true SERIALIZABLE isolation, not just snapshot isolation
# Required for correctness in banking/financial applications
```

Component 5: Saga Pattern with Real Business Examples

Enhanced with multiple real-world workflows:

```python
class OrderSaga:
    """
    Real-world e-commerce order processing
    Each step can fail, needs compensation
    """
    
    def create_order(self, user_id, items):
        steps = [
            {
                'action': self._reserve_inventory,
                'compensation': self._release_inventory,
                'params': {'items': items}
            },
            {
                'action': self._charge_credit_card,
                'compensation': self._refund_payment,
                'params': {'user_id': user_id, 'amount': self._calculate_total(items)}
            },
            {
                'action': self._create_shipping_label,
                'compensation': self._cancel_shipping,
                'params': {'user_id': user_id, 'items': items}
            },
            {
                'action': self._send_confirmation_email,
                'compensation': None,  # No compensation for email
                'params': {'user_id': user_id, 'order_id': self.order_id}
            }
        ]
        
        executed_steps = []
        
        for step in steps:
            try:
                step['action'](**step['params'])
                executed_steps.append(step)
            except Exception as e:
                # Compensate in reverse order
                for executed in reversed(executed_steps):
                    if executed['compensation']:
                        executed['compensation'](**executed['params'])
                raise OrderFailedError(f"Step failed: {e}")
        
        return self.order_id

# Added: More Real-World Saga Examples

class RideBookingSaga:
    """Uber/Lyft-style ride booking"""
    def book_ride(self, rider_id, pickup, destination):
        steps = [
            {'action': self._find_available_driver, 'compensation': None},
            {'action': self._calculate_fare, 'compensation': None},
            {'action': self._charge_rider, 'compensation': self._refund_rider},
            {'action': self._assign_driver, 'compensation': self._release_driver},
            {'action': self._start_trip, 'compensation': self._cancel_trip}
        ]
        # If charging fails after finding driver: refund and release driver

class TravelBookingSaga:
    """Expedia-style hotel + flight booking"""
    def book_travel(self, user_id, flight_details, hotel_details):
        steps = [
            {'action': self._book_flight, 'compensation': self._cancel_flight},
            {'action': self._book_hotel, 'compensation': self._cancel_hotel},
            {'action': self._reserve_car, 'compensation': self._cancel_car},
            {'action': self._charge_total, 'compensation': self._refund_all}
        ]
        # If hotel booking fails: cancel flight, don't book car
```

Component 6: Smart Transaction Router with Decision Framework

Enhanced with ultra-clear rule-of-thumb:

```python
class TransactionRouter:
    """
    Chooses protocol based on transaction characteristics
    Interview Rule-of-Thumb:
    
    Need atomic money transfers? → 2PC
    Need scalable indexing/analytics? → Percolator (OCC)
    Need multi-step business workflows? → Sagas  
    Need global consistency? → Spanner/TrueTime
    Need serializable without clocks? → CockroachDB
    Need high contention handling? → 2PC or pessimistic locking
    """
    
    def choose_protocol(self, transaction):
        features = self._extract_features(transaction)
        
        # Decision tree (simplified for interviews)
        if features['requires_serializable']:
            return '2pc'
        elif features['num_shards'] == 1:
            return 'percolator'  # Single-shard optimization
        elif features['estimated_duration'] > 10:  # seconds
            return 'saga'  # Long-running
        elif features['contention_risk'] > 0.3:
            return '2pc'  # High conflict needs locking
        else:
            return 'percolator'  # Default OCC
    
    def _extract_features(self, transaction):
        return {
            'num_shards': len(transaction['participants']),
            'read_write_ratio': transaction['reads'] / max(transaction['writes'], 1),
            'contention_risk': self._estimate_contention(transaction),
            'estimated_duration': self._estimate_duration(transaction),
            'requires_serializable': transaction.get('isolation') == 'serializable'
        }
```

---

5. Isolation Levels: What Each Protocol Guarantees

Enhanced with explicit isolation level table:

```python
isolation_levels = {
    "2PC": {
        "Protocol": "Pessimistic Locking",
        "Isolation": "Serializable (strongest)",
        "Anomalies Prevented": "All: dirty reads, non-repeatable reads, phantoms, write skew",
        "Use Case": "Banking transfers, inventory management",
        "Trade-off": "Blocks on coordinator failure"
    },
    "Percolator": {
        "Protocol": "Optimistic Concurrency Control (OCC)",
        "Isolation": "Snapshot Isolation",
        "Anomalies Prevented": "Dirty reads, non-repeatable reads",
        "Anomalies Possible": "Write skew (business invariants can break)",
        "Use Case": "Google Search index, analytics, logging",
        "Trade-off": "Aborts under high contention"
    },
    "CockroachDB": {
        "Protocol": "OCC + Read Refresh",
        "Isolation": "Serializable Snapshot Isolation",
        "Anomalies Prevented": "All including write skew",
        "How": "Re-reads all keys before commit, aborts if any changed",
        "Use Case": "General distributed SQL, financial apps",
        "Trade-off": "Higher latency due to read refresh"
    },
    "Sagas": {
        "Protocol": "Compensating Actions",
        "Isolation": "Eventual (business-level consistency)",
        "Anomalies Prevented": "None at database level",
        "Consistency": "Applied at business logic layer",
        "Use Case": "E-commerce, ride booking, travel reservations",
        "Trade-off": "Complex compensation logic"
    },
    "Spanner": {
        "Protocol": "2PC + TrueTime",
        "Isolation": "External Consistency",
        "Anomalies Prevented": "All + commit order matches real-time",
        "How": "Commit wait (ε ms) ensures global ordering",
        "Use Case": "Google Ads, global financial systems",
        "Trade-off": "Higher latency due to commit wait"
    }
}

# Key insight: Higher isolation = lower performance
# Choose the minimum isolation your business needs
# Snapshot isolation works for 90% of applications
# Serializable needed for financial invariants
```

---

6. Failure Modes & Solutions

Failure 1: 2PC Coordinator Crash

```python
class NonBlocking2PC:
    def __init__(self):
        self.timeout = 30  # seconds
        self.recovery_log = WriteAheadLog('/2pc/recovery.log')
    
    def prepare_with_timeout(self, participant, txid):
        """Prepare with automatic timeout-based abort"""
        try:
            # Log prepare before sending
            self.recovery_log.write(f'prepare:{txid}:{participant}')
            
            # Send with timeout
            return participant.prepare(txid, timeout=self.timeout)
        except TimeoutError:
            # Timeout → assume abort
            self.recovery_log.write(f'timeout:{txid}:{participant}')
            return False
```

Failure 2: Clock Skew Breaking Serializability

```python
class TrueTimeTransaction:
    """
    Spanner's solution: Bounded clock uncertainty
    External consistency: If T1 commits before T2 starts in real time,
    then T1's timestamp < T2's timestamp in system time
    """
    def __init__(self, epsilon_ms=7):
        self.epsilon = epsilon_ms  # Max clock error
    
    def commit_with_external_consistency(self):
        """
        Wait until commit is definitely in the past globally
        """
        commit_ts = truetime.now().latest
        
        # Wait epsilon to ensure no earlier commit could have this timestamp
        wait_until = commit_ts + self.epsilon
        truetime.sleep_until(wait_until)
        
        # Now safe to acknowledge to client
        return commit_ts
```

Enhanced: Write-Write Conflict in Percolator (Explicit Example)

```python
class WriteWriteConflictExample:
    """
    Demonstrates Percolator's optimistic conflict detection
    """
    def demonstrate(self):
        print("""
        Timeline showing write-write conflict:
        
        T=0: Tx1 starts (start_ts=10), reads key A=100
        T=1: Tx2 starts (start_ts=20), reads key A=100  
        T=2: Tx1 prewrites A=90 (succeeds, gets lock at TS=10)
        T=3: Tx2 tries to prewrite A=80 (FAILS! sees lock from Tx1 at TS=10)
        T=4: Tx2 aborts, will retry with new start_ts=30
        T=5: Tx1 commits (commit_ts=25)
        T=6: Tx2 retry: reads A=90 (new value), prewrites A=80 (now succeeds)
        
        Key insight: 
        - OCC detects conflicts at COMMIT time, not read time
        - No blocking during reads (unlike pessimistic locking)
        - Aborts increase under high contention
        
        This is why Percolator works great for:
        - Search indexing (low contention, many reads)
        - Analytics (batch writes, few conflicts)
        
        But NOT for:
        - Hot counters (high contention → many aborts)
        - Auction systems (last write should win)
        """)
```

Failure 4: Cross-Shard Foreign Keys

```python
class DeferredConstraintValidation:
    def validate_async(self, constraint):
        """
        Validate in background, fix violations eventually
        Cross-shard constraints can't be validated atomically
        """
        self.validation_queue.put(constraint)
        return True  # Optimistic acceptance
```

---

7. Hardening for Production

Optimization 1: Parallel 2PC

```python
class Parallel2PC:
    """
    Execute independent operations in parallel
    Reduces latency from O(n) to O(1) for independent ops
    """
    def execute_parallel(self, operations):
        independent_sets = self._find_independent_operations(operations)
        
        with ThreadPoolExecutor() as executor:
            futures = []
            for op_set in independent_sets:
                future = executor.submit(self._execute_operation_set, op_set)
                futures.append(future)
            
            results = [f.result() for f in futures]
        
        return self._combine_results(results)
```

Optimization 2: Hybrid Logical Clocks

```python
class HybridLogicalClock:
    """
    CockroachDB's approach: Combine physical + logical time
    No need for TrueTime's GPS/atomic clocks
    Preserves causal ordering across data centers
    """
    def __init__(self, node_id):
        self.node_id = node_id
        self.last_physical = 0
        self.logical = 0
    
    def now(self):
        physical = int(time.time() * 1000)
        
        if physical > self.last_physical:
            self.last_physical = physical
            self.logical = 0
        else:
            self.logical += 1
        
        return (self.last_physical, self.logical, self.node_id)
```

Optimization 3: Read-Only Transaction Optimization

```python
class ReadOnlyOptimizer:
    """
    Read-only transactions don't need locking
    Can use any consistent snapshot
    """
    def execute_read_only(self, query, consistency='strong'):
        if consistency == 'strong':
            # Read latest snapshot
            snapshot_ts = storage.get_latest_snapshot()
            return self._execute_at_snapshot(query, snapshot_ts)
        elif consistency == 'stale':
            # Read from replica with bounded staleness
            replica_ts = self._get_replica_snapshot(max_staleness_ms=1000)
            return self._execute_at_snapshot(query, replica_ts)
```

---

8. Interview Cheatsheet & Decision Framework

Enhanced with ultra-clear rules:

Protocol Decision Framework

```python
def choose_transaction_protocol(requirements):
    """
    Interview Rule-of-Thumb (memorize this):
    
    1. Atomic money transfers? → 2PC (strong consistency needed)
    2. Scalable indexing/analytics? → Percolator/OCC (low contention)
    3. Multi-step business workflow? → Sagas (needs compensation)
    4. Global consistency across continents? → Spanner/TrueTime
    5. High contention hot keys? → 2PC or pessimistic locking
    6. General distributed SQL? → CockroachDB (serializable OCC)
    
    Default: Percolator for most cases (90% of applications)
    """
    if requirements['atomic_money_transfers']:
        return "2PC (banking, financial transfers)"
    
    elif requirements['scalable_indexing_or_analytics']:
        return "Percolator/OCC (Google Search, Bigtable)"
    
    elif requirements['multi_step_business_workflow']:
        return "Sagas (e-commerce, ride booking, travel)"
    
    elif requirements['global_consistency_across_continents']:
        return "Spanner/TrueTime (Google Ads, global banking)"
    
    elif requirements['high_contention_hot_keys']:
        return "2PC or pessimistic locking (avoid OCC aborts)"
    
    elif requirements['serializable_without_locks']:
        return "CockroachDB (read refresh for write skew)"
    
    else:
        return "Percolator (default for most distributed apps)"
```

Production Checklist

```markdown
✅ Timeout-based recovery for stuck transactions
✅ Deadlock detection (wait-for graphs)  
✅ Write-ahead logging for crash recovery
✅ Metrics: commit/abort rates, latency percentiles
✅ Automatic retry for aborted transactions
✅ Protocol choice based on workload pattern
✅ Read-only transaction optimization
✅ Cross-shard constraint validation (async)
✅ Primary lock optimization for Percolator
✅ Read refresh for serializable isolation (CockroachDB)
```

Common Interview Questions & Answers

Enhanced with isolation level insights:

```python
qa = {
    "Q: How do you handle coordinator failure in 2PC?": 
    "A: Timeout-based recovery with write-ahead logging + participants abort after timeout unless they see commit in recovery log.",
    
    "Q: Why does Percolator need a timestamp oracle?":
    "A: To establish global ordering without locking. Timestamps determine serialization order for Snapshot Isolation.",
    
    "Q: What isolation level does Percolator provide?":
    "A: Snapshot Isolation (not Serializable). It prevents dirty reads and non-repeatable reads but allows WRITE SKEW.",
    
    "Q: How does CockroachDB prevent write skew?":
    "A: Read refresh before commit - re-reads all keys in read set at a newer timestamp, aborts if any changed.",
    
    "Q: When would you use Sagas over 2PC?":
    "A: For long-running business processes (e-commerce, travel) where blocking for seconds is unacceptable.",
    
    "Q: What's the tradeoff between OCC and pessimistic locking?":
    "A: OCC has lower latency in low contention, higher abort rates in high contention. Choose based on workload.",
    
    "Q: Why isn't 3PC used in production?":
    "A: Breaks under network partitions - both sides can commit independently, causing irreversible data corruption.",
    
    "Q: What's the primary lock optimization in Percolator?":
    "A: Designate one key as 'primary' - commit to it first. Recovery checks only this key to know entire transaction state (O(1) recovery)."
}
```

---

9. What You've Built

Protocol Comparison Summary

```python
protocol_comparison = {
    "2PC": {
        "Best for": "Atomic money transfers, inventory management",
        "Isolation": "Serializable (strongest)",
        "Failure mode": "Blocks on coordinator crash",
        "Real use": "Traditional banking, XA transactions",
        "Interview tip": "Use when you need ACID across shards"
    },
    "Percolator": {
        "Best for": "Search indexing, analytics, logging",
        "Isolation": "Snapshot Isolation (watch for write skew)",
        "Failure mode": "Aborts under high contention",
        "Real use": "Google Search, Bigtable indexing",
        "Interview tip": "Primary lock optimization makes recovery O(1)"
    },
    "CockroachDB": {
        "Best for": "General OLTP with serializable guarantees",
        "Isolation": "Serializable Snapshot Isolation",
        "Failure mode": "Aborts on write skew (read refresh)",
        "Real use": "Cloud-native distributed SQL",
        "Interview tip": "Read refresh catches write skew that SI misses"
    },
    "Sagas": {
        "Best for": "E-commerce, ride booking, travel reservations",
        "Isolation": "Eventual (business-level consistency)",
        "Failure mode": "Complex compensation logic",
        "Real use": "Amazon order processing, Uber rides",
        "Interview tip": "Use for long-running business workflows"
    },
    "Spanner": {
        "Best for": "Global financial systems",
        "Isolation": "External Consistency (strongest possible)",
        "Failure mode": "Higher latency due to commit wait",
        "Real use": "Google Ads, global banking",
        "Interview tip": "TrueTime + commit wait gives global ordering"
    }
}
```

Key Insights:

1. No free lunch: CAP theorem applies - choose protocol based on business needs
2. Timestamp ordering replaces locking in scalable systems (Percolator, Spanner)
3. Recovery is as important as the happy path (primary lock optimization)
4. Different workloads need different protocols - no one-size-fits-all
5. Isolation levels matter - understand what each protocol guarantees:
   · Serializable: 2PC, CockroachDB (with read refresh)
   · Snapshot Isolation: Percolator (write skew possible)
   · Eventual: Sagas (business-level consistency)
   · External Consistency: Spanner (stronger than serializable)

This knowledge powers:

· Banking systems (2PC for atomic transfers)
· Google Search (Percolator for indexing with Snapshot Isolation)
· E-commerce (Sagas for order processing with compensation)
· Global databases (Spanner for worldwide External Consistency)
· Modern distributed SQL (CockroachDB for Serializable OCC)

---

Next Episode: Episode 3.6 — Global Databases (Spanner)

We'll build TrueTime, understand why ε = 7ms matters, and create a database where commits in Tokyo are instantly visible in New York with External Consistency.

Ready for global consistency? Let's build a database that treats the Earth as one computer.